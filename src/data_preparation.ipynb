{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alipi\\Desktop\\Data Attack\\eren-yeager\\src\\data_preparation.ipynb Cell 1\u001b[0m in \u001b[0;36m6\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df[\u001b[39m'\u001b[39m\u001b[39mLongitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m occ \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([read_dataset(\u001b[39m2016\u001b[39;49m), read_dataset(\u001b[39m2017\u001b[39m)])\u001b[39m#,read_dataset(2018)])#, read_dataset(2019)])#, read_dataset(2020)])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m occ[\u001b[39m'\u001b[39m\u001b[39mDataOcorrencia\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_datetime(occ[\u001b[39m'\u001b[39m\u001b[39mDataOcorrencia\u001b[39m\u001b[39m'\u001b[39m], \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m%\u001b[39m\u001b[39mm/\u001b[39m\u001b[39m%\u001b[39m\u001b[39mY \u001b[39m\u001b[39m%\u001b[39m\u001b[39mH:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mM:\u001b[39m\u001b[39m%\u001b[39m\u001b[39mS\u001b[39m\u001b[39m'\u001b[39m, errors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcoerce\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m \u001b[39mprint\u001b[39m(occ[\u001b[39m'\u001b[39m\u001b[39mDataOcorrencia\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32mc:\\Users\\alipi\\Desktop\\Data Attack\\eren-yeager\\src\\data_preparation.ipynb Cell 1\u001b[0m in \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_dataset\u001b[39m(year):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     \u001b[39m# Read the database .CSV\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m         \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mhttps://raw.githubusercontent.com/centraldedados/protecao_civil/master/data/anpc-%7Byear%7D.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m         sep \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m         on_bad_lines\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mskip\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     \u001b[39m# We replace the \",\" with \".\" to facilitate processing\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alipi/Desktop/Data%20Attack/eren-yeager/src/data_preparation.ipynb#W0sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     df[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mto_numeric(df[\u001b[39m'\u001b[39m\u001b[39mLatitude\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:317\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    312\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    313\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    314\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    315\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(inspect\u001b[39m.\u001b[39mcurrentframe()),\n\u001b[0;32m    316\u001b[0m     )\n\u001b[1;32m--> 317\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1729\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1727\u001b[0m     is_text \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1728\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1729\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1730\u001b[0m     f,\n\u001b[0;32m   1731\u001b[0m     mode,\n\u001b[0;32m   1732\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1733\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1734\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1735\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1736\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1737\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1738\u001b[0m )\n\u001b[0;32m   1739\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1740\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:714\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    711\u001b[0m     codecs\u001b[39m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    713\u001b[0m \u001b[39m# open URLs\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m ioargs \u001b[39m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    715\u001b[0m     path_or_buf,\n\u001b[0;32m    716\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[0;32m    717\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[0;32m    718\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[0;32m    719\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[0;32m    720\u001b[0m )\n\u001b[0;32m    722\u001b[0m handle \u001b[39m=\u001b[39m ioargs\u001b[39m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    723\u001b[0m handles: \u001b[39mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:364\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[39m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    363\u001b[0m req_info \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[39m=\u001b[39mstorage_options)\n\u001b[1;32m--> 364\u001b[0m \u001b[39mwith\u001b[39;00m urlopen(req_info) \u001b[39mas\u001b[39;00m req:\n\u001b[0;32m    365\u001b[0m     content_encoding \u001b[39m=\u001b[39m req\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mContent-Encoding\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    366\u001b[0m     \u001b[39mif\u001b[39;00m content_encoding \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgzip\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    367\u001b[0m         \u001b[39m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:266\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[39mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[39mthe stdlib.\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39murllib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrequest\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[39mreturn\u001b[39;00m urllib\u001b[39m.\u001b[39mrequest\u001b[39m.\u001b[39murlopen(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[39m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[39mreturn\u001b[39;00m opener\u001b[39m.\u001b[39;49mopen(url, data, timeout)\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[39mfor\u001b[39;00m processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_response\u001b[39m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[39m=\u001b[39m meth(req, response)\n\u001b[0;32m    527\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[39m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m code \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparent\u001b[39m.\u001b[39;49merror(\n\u001b[0;32m    635\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mhttp\u001b[39;49m\u001b[39m'\u001b[39;49m, request, response, code, msg, hdrs)\n\u001b[0;32m    637\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[39m=\u001b[39m (\u001b[39mdict\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdefault\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttp_error_default\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_chain(\u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[39mfor\u001b[39;00m handler \u001b[39min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    497\u001b[0m     \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\alipi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhttp_error_default\u001b[39m(\u001b[39mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(req\u001b[39m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "\n",
    "\n",
    "ocorrencias = pd.read_csv('../data/data_2016.csv', sep = ',')\n",
    "\n",
    "# Join all csvs in a single pandas dataFrame\n",
    "ocorrencias2016 = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/centraldedados/protecao_civil/master/data/anpc-2016.csv', \n",
    "    sep = ',',\n",
    "    on_bad_lines='skip',\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "ocorrencias2017 = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/centraldedados/protecao_civil/master/data/anpc-2017.csv', \n",
    "    sep = ',',\n",
    "    on_bad_lines='skip',\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "ocorrencias2018 = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/centraldedados/protecao_civil/master/data/anpc-2018.csv', \n",
    "    sep = ',',\n",
    "    on_bad_lines='skip',\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "ocorrencias2019 = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/centraldedados/protecao_civil/master/data/anpc-2019.csv', \n",
    "    sep = ',',\n",
    "    on_bad_lines='skip',\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "ocorrencias2020 = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/centraldedados/protecao_civil/master/data/anpc-2020.csv', \n",
    "    sep = ',',\n",
    "    on_bad_lines='skip',\n",
    "    low_memory=False\n",
    ")\n",
    "\n",
    "ocorrencias = pd.concat([ocorrencias2016, ocorrencias2017, ocorrencias2018, ocorrencias2019, ocorrencias2020], axis=1)\n",
    "\n",
    "# Replace the commas in the Latitude/Longitude columns with dots\n",
    "ocorrencias['Latitude'] = pd.to_numeric(ocorrencias['Latitude'].replace(',', '.'))\n",
    "ocorrencias['Longitude'] = pd.to_numeric(ocorrencias['Longitude'].replace(',', '.'))\n",
    "\n",
    "#data_2016\n",
    "#data_2016_densidade (merge com densidade_populacional_2016)\n",
    "#data_2016_densidade_weekday (adition of weekday column)\n",
    "#ocorrencias_clean (????????????????)\n",
    "#ocorrencias_clean_extras (????????)\n",
    "#ocorrencias_clean_extras_edgar (adition of holidays)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alipi\\AppData\\Local\\Temp\\ipykernel_25948\\2369205207.py:7: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n",
      "C:\\Users\\alipi\\AppData\\Local\\Temp\\ipykernel_25948\\2369205207.py:7: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Numero', 'DataOcorrencia', 'DataFechoOperacional', 'Natureza',\n",
      "       'EstadoOcorrencia', 'Distrito', 'Concelho', 'Freguesia', 'Localidade',\n",
      "       'Latitude', 'Longitude', 'NumeroMeiosTerrestresEnvolvidos',\n",
      "       'NumeroOperacionaisTerrestresEnvolvidos', 'NumeroMeiosAereosEnvolvidos',\n",
      "       'NumeroOperacionaisAereosEnvolvidos', 'Date'],\n",
      "      dtype='object')\n",
      "<bound method NDFrame.head of                Numero      DataOcorrencia DataFechoOperacional  \\\n",
      "698     2016030035371 2016-05-11 23:58:00  2016-05-12 00:40:00   \n",
      "699     2016070010240 2016-05-11 23:43:00  2016-05-12 00:17:00   \n",
      "700     2016120008794 2016-05-11 23:38:00  2016-05-12 00:04:00   \n",
      "701     2016060020439 2016-05-11 23:35:00  2016-05-12 00:20:00   \n",
      "702     2016150039864 2016-05-11 23:24:00  2016-05-12 00:02:00   \n",
      "...               ...                 ...                  ...   \n",
      "234790  2018010106781 2018-12-31 00:47:00  2018-12-31 01:40:00   \n",
      "234791  2018080056438 2018-12-31 00:42:00  2018-12-31 02:23:00   \n",
      "234792  2018020033174 2018-12-31 00:37:00  2018-12-31 03:25:00   \n",
      "234793  2018030102025 2018-12-31 00:34:00  2018-12-31 02:20:00   \n",
      "234794  2018150114406 2018-12-31 00:01:00  2019-01-01 00:00:00   \n",
      "\n",
      "                                                 Natureza EstadoOcorrencia  \\\n",
      "698     Riscos Tecnológicos / Incêndios Urbanos ou em ...     Falso Alarme   \n",
      "699     Riscos Tecnológicos / Incêndios Urbanos ou em ...     Falso Alarme   \n",
      "700     Protecção e Assistência a Pessoas e Bens / Ass...        Encerrada   \n",
      "701     Protecção e Assistência a Pessoas e Bens / Ass...        Encerrada   \n",
      "702     Protecção e Assistência a Pessoas e Bens / Ass...        Encerrada   \n",
      "...                                                   ...              ...   \n",
      "234790  Riscos Mistos / Incêndios Rurais / Povoamento ...     Falso Alarme   \n",
      "234791  Protecção e Assistência a Pessoas e Bens / Ass...        Encerrada   \n",
      "234792  Protecção e Assistência a Pessoas e Bens / Ass...        Encerrada   \n",
      "234793  Protecção e Assistência a Pessoas e Bens / Ass...        Encerrada   \n",
      "234794  Protecção e Assistência a Pessoas e Bens / Ass...        Encerrada   \n",
      "\n",
      "          Distrito              Concelho                         Freguesia  \\\n",
      "698          BRAGA                 BRAGA                 Braga (São Vítor)   \n",
      "699          ÉVORA                 ÉVORA  Malagueira e Horta das Figueiras   \n",
      "700     PORTALEGRE            PORTALEGRE                 Sé e São Lourenço   \n",
      "701        COIMBRA       FIGUEIRA DA FOZ                           Quiaios   \n",
      "702        SETÚBAL              SESIMBRA                   Quinta do Conde   \n",
      "...            ...                   ...                               ...   \n",
      "234790      AVEIRO                AROUCA                          Mansores   \n",
      "234791        FARO               ALJEZUR                           Aljezur   \n",
      "234792        BEJA  FERREIRA DO ALENTEJO           Figueira dos Cavaleiros   \n",
      "234793       BRAGA              BARCELOS                           Remelhe   \n",
      "234794     SETÚBAL               SETÚBAL                              Sado   \n",
      "\n",
      "                                      Localidade   Latitude  Longitude  \\\n",
      "698                              PRAÇA DO BOCAGE  41.557726  -8.406451   \n",
      "699                                        Évora  38.545030  -7.911157   \n",
      "700     UNIÃO DAS FREGUESIAS DA SÉ E SÃO LOURENÇ  39.290952  -7.432146   \n",
      "701                                      Ervedal  40.221907  -8.818046   \n",
      "702                              QUINTA DO CONDE  38.551927  -9.063159   \n",
      "...                                          ...        ...        ...   \n",
      "234790                                  MANSORES  40.930615  -8.364654   \n",
      "234791                            ALJEZUR  - HBA  37.300808  -8.793034   \n",
      "234792                   Santa Margarida do Sado  38.107288  -8.283967   \n",
      "234793                                   REMELHE  41.488930  -8.607896   \n",
      "234794                                 Lisnave    38.496521  -8.796448   \n",
      "\n",
      "        NumeroMeiosTerrestresEnvolvidos  \\\n",
      "698                                 2.0   \n",
      "699                                 2.0   \n",
      "700                                 1.0   \n",
      "701                                 2.0   \n",
      "702                                 1.0   \n",
      "...                                 ...   \n",
      "234790                              1.0   \n",
      "234791                              1.0   \n",
      "234792                              2.0   \n",
      "234793                              1.0   \n",
      "234794                              2.0   \n",
      "\n",
      "        NumeroOperacionaisTerrestresEnvolvidos  NumeroMeiosAereosEnvolvidos  \\\n",
      "698                                        8.0                          0.0   \n",
      "699                                        6.0                          0.0   \n",
      "700                                        3.0                          0.0   \n",
      "701                                        4.0                          0.0   \n",
      "702                                        2.0                          0.0   \n",
      "...                                        ...                          ...   \n",
      "234790                                     5.0                          0.0   \n",
      "234791                                     2.0                          0.0   \n",
      "234792                                     4.0                          0.0   \n",
      "234793                                     3.0                          0.0   \n",
      "234794                                    13.0                          0.0   \n",
      "\n",
      "        NumeroOperacionaisAereosEnvolvidos        Date  \n",
      "698                                    0.0  2016-05-11  \n",
      "699                                    0.0  2016-05-11  \n",
      "700                                    0.0  2016-05-11  \n",
      "701                                    0.0  2016-05-11  \n",
      "702                                    0.0  2016-05-11  \n",
      "...                                    ...         ...  \n",
      "234790                                 0.0  2018-12-31  \n",
      "234791                                 0.0  2018-12-31  \n",
      "234792                                 0.0  2018-12-31  \n",
      "234793                                 0.0  2018-12-31  \n",
      "234794                                 0.0  2018-12-31  \n",
      "\n",
      "[573254 rows x 16 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import datetime \n",
    "\n",
    "def read_dataset(year):\n",
    "    # Read the database .CSV\n",
    "    df = pd.read_csv(\n",
    "        f'https://raw.githubusercontent.com/centraldedados/protecao_civil/master/data/anpc-{year}.csv', \n",
    "        sep = ',', \n",
    "        on_bad_lines='skip'\n",
    "    )\n",
    "\n",
    "    # We replace the \",\" with \".\" to facilitate processing\n",
    "    df['Latitude'] = pd.to_numeric(df['Latitude'].str.replace(',', '.'))\n",
    "    df['Longitude'] = pd.to_numeric(df['Longitude'].str.replace(',', '.'))\n",
    "    return df\n",
    "\n",
    "# Joins as many datasets as possible (more than 3 causes an error due to its size)\n",
    "occ = pd.concat([read_dataset(2016), read_dataset(2017), read_dataset(2018)])\n",
    "\n",
    "# Transforms dates from a string to a DateTime object\n",
    "occ['DataOcorrencia'] = pd.to_datetime(occ['DataOcorrencia'], format='%d/%m/%Y %H:%M:%S', errors='coerce') \n",
    "occ['DataFechoOperacional'] = pd.to_datetime(occ['DataFechoOperacional'], format='%d/%m/%Y %H:%M:%S', errors='coerce')\n",
    "\n",
    "# Removes the time part of the DateTime\n",
    "occ['Date'] = occ['DataOcorrencia'].dt.date\n",
    "\n",
    "# Removes rows with nulls in these columns\n",
    "occ = occ.dropna(subset=[\"DataOcorrencia\", \"Latitude\"])\n",
    "\n",
    "# Drops the rows where NumeroOperacionaisTerrestresEnvolvidos is bigger than 2000\n",
    "occ = occ.loc[occ['NumeroOperacionaisTerrestresEnvolvidos'] < 2000]\n",
    "\n",
    "# Atypical values of latitude and longitude are filtered \n",
    "occ.loc[occ['Latitude'] > 43, 'Latitude'] /= 1000\n",
    "occ.loc[occ['Longitude'] > 0, 'Longitude'] *= -1\n",
    "occ.loc[occ['Longitude'] < -1000, 'Longitude'] /= 1000\n",
    "\n",
    "\n",
    "# Atypical combinations of latitude and longitude are filtered \n",
    "occ = occ.loc[(occ['Longitude'] < -6) & (occ['Longitude'] > -10) & (occ['Latitude'] < 43) & (occ['Latitude'] > 36)]\n",
    "\n",
    "# Removed rows older than 11 May 2016 due to inconsistency from it\n",
    "occ = occ.loc[occ['Date'] >= datetime.date(year=2016, month=5, day=11)]\n",
    "\n",
    "#data_2016\n",
    "#data_2016_densidade (merge com densidade_populacional_2016)\n",
    "#data_2016_densidade_weekday (adition of weekday column)\n",
    "#ocorrencias_clean (????????????????)\n",
    "#ocorrencias_clean_extras (????????)\n",
    "#ocorrencias_clean_extras_edgar (adition of holidays)\n",
    "\n",
    "print(occ.columns)\n",
    "print(occ.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "densidade_populacional = pd.read_csv('../data/densidade_populacional_2016.csv')\n",
    "\n",
    "# Assures uppercase compatiblity between these dataframes \n",
    "densidade_populacional[\"Concelho\"] = densidade_populacional[\"Concelho\"].str.upper()\n",
    "\n",
    "# Merge them by \"Concelho\" matches\n",
    "occ = pd.merge(occ, densidade_populacional, on = \"Concelho\")\n",
    "\n",
    "# Removes extra spaces and replaces commas with dots so that Densidade is transformed into a float\n",
    "occ['Densidade'] = occ['Densidade'].str.replace(' ', '').str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698       2\n",
      "699       2\n",
      "700       2\n",
      "701       2\n",
      "702       2\n",
      "         ..\n",
      "234790    0\n",
      "234791    0\n",
      "234792    0\n",
      "234793    0\n",
      "234794    0\n",
      "Name: Weekday, Length: 573254, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create a new column \"weekday\" and fill it with the weekday number\n",
    "occ['Weekday'] = occ['DataOcorrencia'].apply(lambda x: x.weekday())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698       False\n",
      "699       False\n",
      "700       False\n",
      "701       False\n",
      "702       False\n",
      "          ...  \n",
      "234790    False\n",
      "234791    False\n",
      "234792    False\n",
      "234793    False\n",
      "234794    False\n",
      "Name: Holiday, Length: 573254, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "\n",
    "with open('../data/nationalHolidays.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    yearlyNationalHolidays = [row[0] for row in reader]\n",
    "\n",
    "\n",
    "with open('../data/regionalHolidays.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    yearlyRegionalHolidays = [(row[0], row[1]) for row in reader]\n",
    "\n",
    "# Calculates easter date for each year and all other holidays based on its date\n",
    "def calculate_easter_date(year):\n",
    "    a = year % 19\n",
    "    b = year // 100\n",
    "    c = year % 100\n",
    "    d = b // 4\n",
    "    e = b % 4\n",
    "    f = (b + 8) // 25\n",
    "    g = (b - f + 1) // 3\n",
    "    h = (19 * a + b - d - g + 15) % 30\n",
    "    i = c // 4\n",
    "    k = c % 4\n",
    "    L = (32 + 2 * e + 2 * i - h - k) % 7\n",
    "    m = (a + 11 * h + 22 * L) // 451\n",
    "    month = (h + L - 7 * m + 114) // 31\n",
    "    day = ((h + L - 7 * m + 114) % 31) + 1\n",
    "\n",
    "    easter = datetime(year=year, month=month, day=day)\n",
    "\n",
    "    carnival = easter - timedelta(days=47)\n",
    "    holy_friday = easter - timedelta(days=2)\n",
    "    easter_monday = easter + timedelta(days=1)\n",
    "    body_of_chirst = easter + timedelta(days=60)\n",
    "\n",
    "    return [f'{carnival.year}-0{carnival.month}-{carnival.day:02d}', \n",
    "            f'{holy_friday.year}-0{holy_friday.month}-{holy_friday.day:02d}',\n",
    "            f'{easter.year}-0{easter.month}-{easter.day:02d}',\n",
    "            f'{easter_monday.year}-0{easter_monday.month}-{easter_monday.day:02d}',\n",
    "            f'{body_of_chirst.year}-0{body_of_chirst.month}-{body_of_chirst.day:02d}']\n",
    "\n",
    "nationalHolidays = []\n",
    "municipalHolidays = []\n",
    "for year in range (2016, 2021):\n",
    "    for date in yearlyNationalHolidays:\n",
    "        nationalHolidays.append(f'{year}-{date}')\n",
    "\n",
    "    for date in calculate_easter_date(year):\n",
    "        nationalHolidays.append(date)\n",
    "\n",
    "    for date in yearlyRegionalHolidays:\n",
    "        municipalHolidays.append((f'{year}-{date[0]}', date[1]))\n",
    "\n",
    "def is_holiday(row):\n",
    "    date = row['DataOcorrencia'].strftime('%Y-%m-%d')\n",
    "    municipality = row['Concelho'].capitalize()\n",
    "    return date in nationalHolidays or (date, municipality) in municipalHolidays\n",
    "\n",
    "occ['Holiday'] = occ.apply(lambda row: is_holiday(row), axis=1)\n",
    "\n",
    "# Saves preparation\n",
    "occ.to_csv('../data/ocorrencias_final.csv', sep = ',', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24597\n",
      "573254\n"
     ]
    }
   ],
   "source": [
    "print(sum(occ['Holiday']))\n",
    "print(len(occ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
