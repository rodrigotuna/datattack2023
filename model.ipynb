{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_scaled_error\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ConvLSTMCell** is the basic building block of the ConvLSTM model. It defines a single ConvLSTM cell that takes as input a tensor and a tuple representing the current state of the cell, and outputs a tensor and a tuple representing the next state of the cell. The cell includes a convolutional layer and four gates (input, forget, output, and cell gates) that are used to update the cell state and hidden state. The output tensor is the hidden state of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
    "\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ConvLSTM** is the main class that creates a ConvLSTM model with multiple layers. It takes as input a tensor and an optional tuple representing the initial hidden state of the model, and returns a tuple of two lists. The first list contains the hidden states of each layer at each timestep, and the second list contains the final hidden states and cell states of each layer. The model includes multiple ConvLSTMCell cells that are stacked on top of each other to create a deeper model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        input_dim: Number of channels in input\n",
    "        hidden_dim: Number of hidden channels\n",
    "        kernel_size: Size of kernel in convolutions\n",
    "        num_layers: Number of LSTM layers stacked on each other\n",
    "        batch_first: Whether or not dimension 0 is the batch or not\n",
    "        bias: Bias or no bias in Convolution\n",
    "        return_all_layers: Return the list of computations for all layers\n",
    "        Note: Will do same padding.\n",
    "    Input:\n",
    "        A tensor of size B, T, C, H, W or T, B, C, H, W\n",
    "    Output:\n",
    "        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
    "            0 - layer_output_list is the list of lists of length T of each output\n",
    "            1 - last_state_list is the list of last states\n",
    "                    each element of the list is a tuple (h, c) for hidden state and memory\n",
    "    Example:\n",
    "        >> x = torch.rand((32, 10, 64, 128, 128))\n",
    "        >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
    "        >> _, last_states = convlstm(x)\n",
    "        >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "                 batch_first=False, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "\n",
    "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor: todo\n",
    "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
    "        hidden_state: todo\n",
    "            None. todo implement stateful\n",
    "        Returns\n",
    "        -------\n",
    "        last_state_list, layer_output\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        b, _, _, h, w = input_tensor.size()\n",
    "\n",
    "        # Implement stateful ConvLSTM\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            # Since the init is done in forward. Can send image size here\n",
    "            hidden_state = self._init_hidden(batch_size=b,\n",
    "                                             image_size=(h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
    "                                                 cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "\n",
    "        return layer_output_list, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "def prepare_data_x(x, window_size):\n",
    "    # perform windowing\n",
    "    n_row = x.shape[0] - window_size + 1\n",
    "    channels = x.shape[1]\n",
    "    width = x.shape[2]\n",
    "    height = x.shape[3]\n",
    "    output = np.lib.stride_tricks.as_strided(x, shape=(n_row,window_size, channels, width, height), strides=(x.strides[0],x.strides[0],x.strides[1],x.strides[2],x.strides[3]))\n",
    "    return output[:-1], output[-1]\n",
    "\n",
    "def prepare_data_y(x, window_size):\n",
    "\n",
    "    output = x[window_size:]\n",
    "    return output\n",
    "\n",
    "def prepare_data(normalized_data_close_price):\n",
    "    data_x, _ = prepare_data_x(normalized_data_close_price, window_size=12)\n",
    "    data_y = prepare_data_y(normalized_data_close_price, window_size=12)\n",
    "\n",
    "    # split dataset\n",
    "\n",
    "    split_index = int(data_y.shape[0]*0.8)\n",
    "    data_x_train = data_x[:split_index]\n",
    "    data_x_val = data_x[split_index:]\n",
    "\n",
    "    data_y_train = data_y[:split_index]\n",
    "    data_y_val = data_y[split_index:]\n",
    "\n",
    "\n",
    "    return split_index, data_x_train, data_y_train, data_x_val, data_y_val\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sergio/Documents/feup/eren-yeager/model.ipynb Cell 7\u001b[0m in \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mMSELoss()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m train_model(model, dataloader, criterion, optimizer, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m predicted_val \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m/home/sergio/Documents/feup/eren-yeager/model.ipynb Cell 7\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m _, output \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m], y)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/env/feup/lib/python3.8/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/env/feup/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        # extract date string from row and parse it as a datetime objsaDect\n",
    "        date_str = row[1]\n",
    "        date = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "        features = row[3:].values.astype(np.float32)\n",
    "        label = row[0].astype(np.float32)\n",
    "        sample = {'date_begin': date, 'features': self.transform(features), 'label': label}\n",
    "        return sample\n",
    "\n",
    "\n",
    "# Define the training loop\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for idx, (x,y) in enumerate(dataloader,0):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            _, output = model(x)\n",
    "            loss = criterion(output[0][0], y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print('Epoch %d, loss: %.3f' % (epoch + 1, running_loss / len(dataloader)))\n",
    "\n",
    "# Load the data\n",
    "dataset = MyDataset('./data/ocorrencias_final.csv')\n",
    "data_grid = np.load('data_grid.npy') \n",
    "data_grid = data_grid.reshape(965, 22, 16, 4)\n",
    "data_grid = np.swapaxes(data_grid, 3, 1)\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "split_index, data_x_train, data_y_train, data_x_val, data_y_val = prepare_data(data_grid)\n",
    "\n",
    "\n",
    "dataset_train = TimeSeriesDataset(data_x_train, data_y_train)\n",
    "dataset_val = TimeSeriesDataset(data_x_val, data_y_val)\n",
    "\n",
    "data_x_train = data_x_train.astype(np.float32)\n",
    "data_y_train = data_y_train.astype(np.float32)\n",
    "\n",
    "dataloader = DataLoader(dataset_train, batch_size=1, shuffle=False, num_workers=12)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=1, shuffle=False, num_workers=12)\n",
    "\n",
    "# Create the model, optimizer and loss function\n",
    "model = ConvLSTM(input_dim=4, hidden_dim=[64, 64, 4], kernel_size=(3, 3), num_layers=3, batch_first=True, bias=True, return_all_layers=False)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.004)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs=30)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predicted_val = []\n",
    "\n",
    "for idx, (x, y) in enumerate(val_dataloader):\n",
    "    x = x.to(device)\n",
    "    _,out = model(x)\n",
    "    out = out[0][0].cpu()\n",
    "    predicted_val.append(out.detach().numpy()[0])\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "predicted_val = np.array(predicted_val)\n",
    "print(predicted_val.shape)\n",
    "print(data_y_val.shape)\n",
    "\n",
    "data_y_val = data_y_val.reshape(191, 1408)\n",
    "predicted_val = predicted_val.reshape(191, 1408)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(data_y_val, predicted_val))\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 1408)\n",
      "(191, 1408)\n",
      "13.398050417386921\n",
      "1.4089250395538317\n"
     ]
    }
   ],
   "source": [
    "predicted_val = np.array(predicted_val)\n",
    "print(predicted_val.shape)\n",
    "print(data_y_val.shape)\n",
    "\n",
    "data_y_val = data_y_val.reshape(191, 1408)\n",
    "predicted_val = predicted_val.reshape(191, 1408)\n",
    "data_y_train = data_y_train.reshape(762, 1408)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(data_y_val, predicted_val))\n",
    "mase = mean_absolute_scaled_error(y_true=data_y_val, y_pred=predicted_val, y_train=data_y_train)\n",
    "print(rmse)\n",
    "print(mase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.86767056e-07 -7.62678393e-11 -4.40937634e-11 -3.97206264e-07\n",
      "  -4.65746089e-05  5.68828778e-03  8.19952220e-06  1.05131476e-04\n",
      "   2.31512566e-03  1.43417667e-04 -5.05817006e-04 -2.32556502e-07\n",
      "  -5.79607518e-09 -2.14864867e-05 -6.24179595e-15 -3.38032532e-15\n",
      "  -1.22259516e-12 -2.05907819e-10 -7.92174590e-11 -5.88010334e-06\n",
      "   3.49845286e-09 -3.51644030e-06]\n",
      " [-8.76098216e-09 -2.78596283e-17 -2.13244060e-15 -6.99649297e-11\n",
      "  -8.56295228e-05 -2.29013473e-04  9.99999881e-01  1.00000000e+00\n",
      "   1.00000000e+00  9.99986410e-01  2.00018345e-04 -6.42973869e-11\n",
      "  -3.01189846e-13 -1.20678436e-14 -2.71970756e-19 -9.25635818e-17\n",
      "  -5.12792489e-17 -3.05491366e-17 -1.20262962e-17 -9.95089081e-12\n",
      "  -3.05241478e-16 -6.61366739e-10]\n",
      " [-8.90262483e-04 -9.76788650e-10 -1.44485259e-08 -3.61932575e-06\n",
      "  -9.05487454e-04  9.99766290e-01  1.00000000e+00  9.99999642e-01\n",
      "   9.99998331e-01  9.99999881e-01  9.99994159e-01  6.04523339e-05\n",
      "   4.84539283e-04  1.00503801e-08 -7.57900338e-08 -5.39941182e-11\n",
      "  -6.19148552e-11 -6.24472609e-12 -9.29492094e-10 -1.50815225e-07\n",
      "  -2.59656120e-12 -3.27865557e-09]\n",
      " [ 9.99339521e-01  7.86700298e-07  1.48989158e-02  9.99070108e-01\n",
      "   4.54806909e-03  3.80638964e-03  9.99999881e-01  9.99993563e-01\n",
      "   9.99999642e-01  9.99999642e-01  9.99998569e-01  1.00000000e+00\n",
      "   9.99993563e-01  1.34943332e-06  4.23805504e-05  5.75668491e-05\n",
      "   2.81466127e-05  2.53029102e-05  3.60121974e-03  7.57483482e-01\n",
      "   2.77589223e-08  4.57756614e-05]\n",
      " [ 1.00000000e+00  9.99984741e-01  9.99999642e-01  9.99989152e-01\n",
      "   9.99929428e-01  8.04545641e-01  9.99997020e-01  9.99977112e-01\n",
      "   9.99975562e-01  9.99999046e-01  9.99993563e-01  9.99998450e-01\n",
      "   9.99998331e-01  9.99999285e-01  9.99999404e-01  9.99995470e-01\n",
      "   1.00000000e+00  9.99999881e-01  9.99999881e-01  9.99999881e-01\n",
      "   9.99994397e-01  7.96794484e-05]\n",
      " [ 1.00000000e+00  9.99372423e-01  9.75023150e-01  9.47383702e-01\n",
      "   9.99806345e-01  9.99894857e-01  9.99986291e-01  9.99997616e-01\n",
      "   9.99994755e-01  9.99999523e-01  9.99999762e-01  9.99993682e-01\n",
      "   9.99998093e-01  9.99989510e-01  9.99970794e-01  9.99994397e-01\n",
      "   9.99997854e-01  9.99995708e-01  9.99999166e-01  9.99999881e-01\n",
      "   9.99996662e-01  4.42023775e-05]\n",
      " [ 1.00000000e+00  9.99053061e-01  9.99502063e-01  9.99837041e-01\n",
      "   9.99972701e-01  8.43518674e-01  9.99858201e-01  9.90723670e-01\n",
      "   9.99993563e-01  9.99997020e-01  9.99998927e-01  9.99986768e-01\n",
      "   9.99991894e-01  9.99989510e-01  9.99993443e-01  9.99999046e-01\n",
      "   9.99999881e-01  1.00000000e+00  9.99991655e-01  9.43940520e-01\n",
      "   9.91151392e-01 -5.92057477e-05]\n",
      " [ 9.99999642e-01  8.01078737e-01  9.99769092e-01  9.91553962e-01\n",
      "   9.99987245e-01  9.99599993e-01  9.99999523e-01  9.91804004e-01\n",
      "   9.99798119e-01  9.99982476e-01  9.99999166e-01  9.99995470e-01\n",
      "   9.99999881e-01  9.99995351e-01  9.99999762e-01  9.99996781e-01\n",
      "   1.00000000e+00  9.99998569e-01  9.99995112e-01  3.07613701e-01\n",
      "   4.55443524e-06 -2.52607435e-07]\n",
      " [ 9.99998689e-01  3.64089727e-01  7.67333329e-01  7.44576693e-01\n",
      "   9.99737084e-01  9.95516360e-01  9.98478115e-01  9.99830365e-01\n",
      "   9.99964237e-01  9.99979496e-01  9.99881387e-01  9.99969482e-01\n",
      "   9.99614954e-01  9.99996543e-01  9.99976635e-01  9.99996901e-01\n",
      "   1.00000000e+00  9.99999642e-01  9.99776423e-01  9.99673605e-01\n",
      "   4.63519463e-08 -7.75753847e-07]\n",
      " [ 9.99278963e-01  7.58878589e-01  6.04686439e-01  8.18145335e-01\n",
      "   9.99989629e-01  9.99983668e-01  9.99847889e-01  9.99904513e-01\n",
      "   9.99729931e-01  9.99999762e-01  1.77334145e-01  9.99999166e-01\n",
      "   9.99676824e-01  9.99999762e-01  9.99926209e-01  9.99414563e-01\n",
      "   9.99998927e-01  9.99991059e-01  9.99975502e-01  9.79732037e-01\n",
      "   7.96360200e-10 -2.60720991e-08]\n",
      " [ 1.02414288e-05  3.92155198e-05  4.40225705e-08  1.12062797e-03\n",
      "   7.10790396e-01  9.85836744e-01  6.19930029e-01  9.99999762e-01\n",
      "   9.97612715e-01  6.63692713e-01  3.63748497e-03  7.78760135e-01\n",
      "   9.97967899e-01  9.99997854e-01  9.99817193e-01  9.99857664e-01\n",
      "   9.99989390e-01  9.99996066e-01  9.99984860e-01  4.32877034e-01\n",
      "   4.35954576e-07 -1.12865841e-07]\n",
      " [-3.78705609e-11 -1.96112463e-17 -1.73400747e-06 -6.98062808e-09\n",
      "   3.90324881e-03  3.70376743e-03  2.90492433e-04  5.60863256e-01\n",
      "   9.99115884e-01  1.15533755e-03  2.26953276e-07  3.50490154e-04\n",
      "   2.43574567e-02  9.63328302e-01  9.98323083e-01  9.93960679e-01\n",
      "   9.99079704e-01  9.99996781e-01  9.99999762e-01  7.58527935e-01\n",
      "   5.13812566e-08 -5.35065169e-07]\n",
      " [-9.12495161e-17 -2.62039272e-22 -8.94486314e-17 -1.83970305e-15\n",
      "  -6.11333206e-12 -6.54026380e-08 -8.14759016e-09  6.33724403e-06\n",
      "   8.52699450e-05 -5.52026904e-08 -9.93117602e-11 -3.60661667e-10\n",
      "  -1.47489201e-10  3.75698204e-04  4.44041789e-01  4.05934639e-03\n",
      "   3.89465898e-01  9.99999166e-01  9.99838352e-01  1.00000000e+00\n",
      "   1.12565471e-10 -2.19404299e-08]\n",
      " [-2.51012115e-15 -8.51721242e-18 -2.53044978e-16 -2.98547603e-19\n",
      "  -7.42747496e-19 -2.14998138e-17 -1.51316904e-12 -1.50427054e-14\n",
      "  -3.30720524e-14 -2.34471513e-13 -1.89729024e-13 -5.50767080e-16\n",
      "  -2.07387146e-11 -7.46767492e-12  8.62266404e-07 -9.14966503e-09\n",
      "   1.19854864e-11  7.38639951e-01  7.62761056e-01  1.64411291e-02\n",
      "   5.98762576e-14 -1.30502167e-06]\n",
      " [-5.53526396e-16 -3.86101569e-19 -2.58366479e-14 -1.72431175e-17\n",
      "  -5.64487117e-18 -4.04572880e-17 -1.94980039e-14 -7.98763517e-17\n",
      "  -6.19773346e-17 -1.11874163e-14 -3.28393932e-15 -2.24469314e-18\n",
      "  -1.30049691e-15 -6.13707597e-17 -7.55373056e-15 -1.50809448e-10\n",
      "  -1.68093664e-10 -2.52263314e-11  5.20678699e-01 -6.13597351e-09\n",
      "  -1.49418835e-16 -6.35057967e-03]\n",
      " [-1.46673642e-07 -1.46497977e-18 -3.25966251e-15 -1.23871874e-13\n",
      "  -8.83146875e-15 -9.38681771e-12 -6.02958217e-09 -4.38427947e-14\n",
      "  -6.03457909e-11 -2.54643702e-12 -4.14350069e-07 -3.79773817e-11\n",
      "  -2.38582274e-08 -3.32581212e-13 -4.13320392e-13 -2.32997122e-10\n",
      "  -5.46704956e-12 -9.25797741e-13 -1.74338853e-12 -1.47639842e-14\n",
      "  -3.96847421e-19 -6.31160635e-09]]\n",
      "(191, 4, 16, 22)\n",
      "(191, 4, 16, 22)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read and build the neural network\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import rotate\n",
    "import imageio\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "\n",
    "model = ConvLSTM(input_dim=4, hidden_dim=[64, 64, 4], kernel_size=(3, 3), num_layers=3, batch_first=True, bias=True, return_all_layers=False)\n",
    "model.load_state_dict(torch.load('model.pth'))\n",
    "model.eval()\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "predicted_val = []\n",
    "\n",
    "for idx, (x, y) in enumerate(val_dataloader):\n",
    "    x = x.to(device)\n",
    "    _,out = model(x)\n",
    "    out = out[0][0].cpu()\n",
    "    predicted_val.append(out.detach().numpy()[0])\n",
    "\n",
    "# print heatmap each predicted_val\n",
    "predicted_val = np.array(predicted_val)\n",
    "print(predicted_val[0][0])\n",
    "#invert the 2d\n",
    "\n",
    "x = predicted_val[0][0]\n",
    "x = rotate(x, angle=90)\n",
    "\n",
    "plt.imshow(x, cmap='hot', interpolation='nearest')\n",
    "\n",
    "#increase the resolution of the heatmap\n",
    "new_size = (x.shape[0]*2, x.shape[1]*2)\n",
    "new_img = ndimage.zoom(x, zoom=(2, 2), order=1)\n",
    "\n",
    "\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(new_img, cmap='hot', interpolation='nearest')\n",
    "plt.savefig('test.png', transparent=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(predicted_val.shape)\n",
    "print(data_y_val.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8799/2864817638.py:19: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  images.append(imageio.imread('heatmap.png'))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images = []\n",
    "\n",
    "feature_num = 1\n",
    "\n",
    "for i in range(0, 191):\n",
    "    x = predicted_val[i][feature_num]\n",
    "    x = rotate(x, angle=90)\n",
    "    new_size = (x.shape[0]*2, x.shape[1]*2)\n",
    "    new_img = ndimage.zoom(x, zoom=(2, 2), order=1) \n",
    "    plt.imshow(new_img, cmap='hot', interpolation='nearest')\n",
    "    #add a colorbar\n",
    "    #add a progress bar to the image of the frames\n",
    "    #plt.text(0.5, 0.5, str(i), fontsize=18, ha='center')\n",
    "    plt.title('Heatmap of predicted values')\n",
    "    \n",
    "\n",
    "\n",
    "    plt.savefig('heatmap.png')\n",
    "    images.append(imageio.imread('heatmap.png'))\n",
    "\n",
    "imageio.mimsave(f'./plots/heatmap_res_feature{feature_num}.gif', images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
