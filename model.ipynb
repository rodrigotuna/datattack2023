{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sktime.performance_metrics.forecasting import mean_absolute_scaled_error\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ConvLSTMCell** is the basic building block of the ConvLSTM model. It defines a single ConvLSTM cell that takes as input a tensor and a tuple representing the current state of the cell, and outputs a tensor and a tuple representing the next state of the cell. The cell includes a convolutional layer and four gates (input, forget, output, and cell gates) that are used to update the cell state and hidden state. The output tensor is the hidden state of the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "\n",
    "        super(ConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
    "\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        c_next = f * c_cur + i * g\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "\n",
    "        return h_next, c_next\n",
    "\n",
    "    def init_hidden(self, batch_size, image_size):\n",
    "        height, width = image_size\n",
    "        return (torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device),\n",
    "                torch.zeros(batch_size, self.hidden_dim, height, width, device=self.conv.weight.device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ConvLSTM** is the main class that creates a ConvLSTM model with multiple layers. It takes as input a tensor and an optional tuple representing the initial hidden state of the model, and returns a tuple of two lists. The first list contains the hidden states of each layer at each timestep, and the second list contains the final hidden states and cell states of each layer. The model includes multiple ConvLSTMCell cells that are stacked on top of each other to create a deeper model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvLSTM(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        input_dim: Number of channels in input\n",
    "        hidden_dim: Number of hidden channels\n",
    "        kernel_size: Size of kernel in convolutions\n",
    "        num_layers: Number of LSTM layers stacked on each other\n",
    "        batch_first: Whether or not dimension 0 is the batch or not\n",
    "        bias: Bias or no bias in Convolution\n",
    "        return_all_layers: Return the list of computations for all layers\n",
    "        Note: Will do same padding.\n",
    "    Input:\n",
    "        A tensor of size B, T, C, H, W or T, B, C, H, W\n",
    "    Output:\n",
    "        A tuple of two lists of length num_layers (or length 1 if return_all_layers is False).\n",
    "            0 - layer_output_list is the list of lists of length T of each output\n",
    "            1 - last_state_list is the list of last states\n",
    "                    each element of the list is a tuple (h, c) for hidden state and memory\n",
    "    Example:\n",
    "        >> x = torch.rand((32, 10, 64, 128, 128))\n",
    "        >> convlstm = ConvLSTM(64, 16, 3, 1, True, True, False)\n",
    "        >> _, last_states = convlstm(x)\n",
    "        >> h = last_states[0][0]  # 0 for layer index, 0 for h index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, kernel_size, num_layers,\n",
    "                 batch_first=False, bias=True, return_all_layers=False):\n",
    "        super(ConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers)\n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_first = batch_first\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "\n",
    "            cell_list.append(ConvLSTMCell(input_dim=cur_input_dim,\n",
    "                                          hidden_dim=self.hidden_dim[i],\n",
    "                                          kernel_size=self.kernel_size[i],\n",
    "                                          bias=self.bias))\n",
    "\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "    def forward(self, input_tensor, hidden_state=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_tensor: todo\n",
    "            5-D Tensor either of shape (t, b, c, h, w) or (b, t, c, h, w)\n",
    "        hidden_state: todo\n",
    "            None. todo implement stateful\n",
    "        Returns\n",
    "        -------\n",
    "        last_state_list, layer_output\n",
    "        \"\"\"\n",
    "        if not self.batch_first:\n",
    "            # (t, b, c, h, w) -> (b, t, c, h, w)\n",
    "            input_tensor = input_tensor.permute(1, 0, 2, 3, 4)\n",
    "\n",
    "        b, _, _, h, w = input_tensor.size()\n",
    "\n",
    "        # Implement stateful ConvLSTM\n",
    "        if hidden_state is not None:\n",
    "            raise NotImplementedError()\n",
    "        else:\n",
    "            # Since the init is done in forward. Can send image size here\n",
    "            hidden_state = self._init_hidden(batch_size=b,\n",
    "                                             image_size=(h, w))\n",
    "\n",
    "        layer_output_list = []\n",
    "        last_state_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "\n",
    "            h, c = hidden_state[layer_idx]\n",
    "            output_inner = []\n",
    "            for t in range(seq_len):\n",
    "                h, c = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :],\n",
    "                                                 cur_state=[h, c])\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)\n",
    "            last_state_list.append([h, c])\n",
    "\n",
    "        if not self.return_all_layers:\n",
    "            layer_output_list = layer_output_list[-1:]\n",
    "            last_state_list = last_state_list[-1:]\n",
    "\n",
    "        return layer_output_list, last_state_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, image_size):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append(self.cell_list[i].init_hidden(batch_size, image_size))\n",
    "        return init_states\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):\n",
    "            param = [param] * num_layers\n",
    "        return param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preparation\n",
    "def prepare_data_x(x, window_size):\n",
    "    # perform windowing\n",
    "    n_row = x.shape[0] - window_size + 1\n",
    "    channels = x.shape[1]\n",
    "    width = x.shape[2]\n",
    "    height = x.shape[3]\n",
    "    output = np.lib.stride_tricks.as_strided(x, shape=(n_row,window_size, channels, width, height), strides=(x.strides[0],x.strides[0],x.strides[1],x.strides[2],x.strides[3]))\n",
    "    return output[:-1], output[-1]\n",
    "\n",
    "def prepare_data_y(x, window_size):\n",
    "\n",
    "    # perform simple moving average\n",
    "    # output = np.convolve(x, np.ones(window_size), 'valid') / window_size\n",
    "    # use the next day as label\n",
    "\n",
    "    output = x[window_size:]\n",
    "    return output\n",
    "\n",
    "def prepare_data(normalized_data_close_price):\n",
    "    data_x, _ = prepare_data_x(normalized_data_close_price, window_size=12)\n",
    "    data_y = prepare_data_y(normalized_data_close_price, window_size=12)\n",
    "\n",
    "    # split dataset\n",
    "\n",
    "    split_index = int(data_y.shape[0]*0.8)\n",
    "    data_x_train = data_x[:split_index]\n",
    "    data_x_val = data_x[split_index:]\n",
    "\n",
    "    data_y_train = data_y[:split_index]\n",
    "    data_y_val = data_y[split_index:]\n",
    "\n",
    "\n",
    "    return split_index, data_x_train, data_y_train, data_x_val, data_y_val\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "\n",
    "        self.x = x.astype(np.float32)\n",
    "        self.y = y.astype(np.float32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.x[idx], self.y[idx])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(762, 12, 4, 16, 22)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Inconsistent list length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/sergio/Documents/feup/eren-yeager/model.ipynb Cell 7\u001b[0m in \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m val_dataloader \u001b[39m=\u001b[39m DataLoader(dataset_val, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m12\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m \u001b[39m# Create the model, optimizer and loss function\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m model \u001b[39m=\u001b[39m ConvLSTM(input_dim\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, hidden_dim\u001b[39m=\u001b[39;49m[\u001b[39m64\u001b[39;49m, \u001b[39m64\u001b[39;49m, \u001b[39m4\u001b[39;49m], kernel_size\u001b[39m=\u001b[39;49m(\u001b[39m3\u001b[39;49m, \u001b[39m3\u001b[39;49m), num_layers\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, bias\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, return_all_layers\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m model \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n",
      "\u001b[1;32m/home/sergio/Documents/feup/eren-yeager/model.ipynb Cell 7\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m hidden_dim \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extend_for_multilayer(hidden_dim, num_layers)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(kernel_size) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(hidden_dim) \u001b[39m==\u001b[39m num_layers:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mInconsistent list length.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dim \u001b[39m=\u001b[39m input_dim\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/sergio/Documents/feup/eren-yeager/model.ipynb#W6sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_dim \u001b[39m=\u001b[39m hidden_dim\n",
      "\u001b[0;31mValueError\u001b[0m: Inconsistent list length."
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        # extract date string from row and parse it as a datetime objsaDect\n",
    "        date_str = row[1]\n",
    "        date = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')\n",
    "        features = row[3:].values.astype(np.float32)\n",
    "        label = row[0].astype(np.float32)\n",
    "        sample = {'date_begin': date, 'features': self.transform(features), 'label': label}\n",
    "        return sample\n",
    "\n",
    "\n",
    "# Define the training loop\n",
    "def train_model(model, dataloader, label, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for idx, (x,y) in enumerate(dataloader,0):\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            _, output = model(x)\n",
    "            loss = criterion(output[0][0], y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print('Epoch %d, loss: %.3f' % (epoch + 1, running_loss / len(dataloader)))\n",
    "\n",
    "# Load the data\n",
    "dataset = MyDataset('./data/ocorrencias_final.csv')\n",
    "data_grid = np.load('data_grid.npy') \n",
    "data_grid = data_grid.reshape(965, 22, 16, 4)\n",
    "data_grid = np.swapaxes(data_grid, 3, 1)\n",
    "\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "split_index, data_x_train, data_y_train, data_x_val, data_y_val = prepare_data(data_grid)\n",
    "\n",
    "print(data_x_train.shape)\n",
    "\n",
    "dataset_train = TimeSeriesDataset(data_x_train, data_y_train)\n",
    "dataset_val = TimeSeriesDataset(data_x_val, data_y_val)\n",
    "\n",
    "#print(\"here\", dataset_train.shape)\n",
    "data_x_train = data_x_train.astype(np.float32)\n",
    "data_y_train = data_y_train.astype(np.float32)\n",
    "\n",
    "dataloader = DataLoader(dataset_train, batch_size=1, shuffle=False, num_workers=12)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=1, shuffle=False, num_workers=12)\n",
    "\n",
    "# Create the model, optimizer and loss function\n",
    "model = ConvLSTM(input_dim=4, hidden_dim=[100, 100, 4], kernel_size=(3, 3), num_layers=3, batch_first=True, bias=True, return_all_layers=False)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Train the model\n",
    "train_model(model, dataloader, data_y_train, criterion, optimizer, num_epochs=30)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "predicted_val = []\n",
    "\n",
    "for idx, (x, y) in enumerate(val_dataloader):\n",
    "    x = x.to(device)\n",
    "    _,out = model(x)\n",
    "    out = out[0][0].cpu()\n",
    "    predicted_val.append(out.detach().numpy()[0])\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "predicted_val = np.array(predicted_val)\n",
    "print(predicted_val.shape)\n",
    "print(data_y_val.shape)\n",
    "\n",
    "data_y_val = data_y_val.reshape(191, 1408)\n",
    "predicted_val = predicted_val.reshape(191, 1408)\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(data_y_val, predicted_val))\n",
    "mase = mean_absolute_scaled_error()\n",
    "print(rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(191, 1408)\n",
      "(191, 1408)\n",
      "13.3979782808327\n"
     ]
    }
   ],
   "source": [
    "predicted_val = np.array(predicted_val)\n",
    "print(predicted_val.shape)\n",
    "print(data_y_val.shape)\n",
    "\n",
    "data_y_val = data_y_val.reshape(191, 1408)\n",
    "predicted_val = predicted_val.reshape(191, 1408)\n",
    "data_y_train = data_y_train.reshape(762, 1408)\n",
    "\n",
    "\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(data_y_val, predicted_val))\n",
    "mase = mean_absolute_scaled_error(y_true=data_y_val, y_pred=predicted_val, y_train=data_y_train)\n",
    "print(rmse)\n",
    "print(mase)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
